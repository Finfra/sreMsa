# Kubernetes Install With Kubespray
## 0. ë³€ìˆ˜ ì…‹íŒ… íŒŒì¼ ìƒì„± í›„ ì‹¤í–‰
* ì•„ë˜ì™€ ê°™ì€ ë‚´ìš©ì„ ~/.bashrcì— ì¶”ê°€í•˜ê³  ì‹¤í–‰í•´ ì¤ë‹ˆë‹¤.
```
su - ubuntu

echo '
export TF_VAR_AWS_ACCESS_KEY="xxxxxxx"
export TF_VAR_AWS_SECRET_KEY="xxxxxxxxxxxxxxx"
export TF_VAR_AWS_REGION="ap-northeast-2"
'>> ~/.bashrc
. ~/.bashrc
```

## 1. OS key ìƒì„± [ìˆìœ¼ë©´ ìƒëµ]
```
ssh-keygen -f ~/.ssh/id_rsa -N ''
```
* cf) ì„¤ì¹˜ ëŒ€ìƒ hostì— Public-key ë°°í¬
    ssh-copy-id root@10.0.2.10

## 2. Terrform ìœ¼ë¡œ host ì…‹íŒ…
```
cd
git clone https://github.com/Finfra/sreMsa
cd ~/sreMsa/lab1.Kubespray/3.InstanceForKubernetes
#terraform destroy -auto-approve
terraform init
terraform apply --auto-approve
source doSetHosts.sh
cd ~
```


## 3. HostsíŒŒì¼ ì…‹íŒ…
```
aws configure
  # security setting
    AWS Access Key ID [None]: xxxxxxxxxx
    AWS Secret Access Key [None]: xxxxxxxxxxxxxxxxxxx
    Default region name [None]: ap-northeast-2
    Default output format [None]: text
cd ~/sreMsa/lab1.Kubespray/3.InstanceForKubernetes
# rm -rf ~/.ssh/known_hosts
bash doSetHosts.sh
```

## 3.1 Ansible Fact Cache ì •ë¦¬ (ë‘ë²ˆì§¸ ì„¤ì¹˜ì‹œ)
ì²« ë²ˆì§¸ ì‹¤í–‰ ì‹¤íŒ¨ì˜ ì£¼ìš” ì›ì¸ì¸ fact cacheë¥¼ ë¯¸ë¦¬ ì •ë¦¬í•©ë‹ˆë‹¤:
```bash
# Ansible fact cache ì •ë¦¬
sudo rm -rf /tmp/ansible_facts*
sudo rm -rf /tmp/kubespray*
sudo rm -rf ~/.ansible/tmp/*

# ê¸°ì¡´ Kubespray ë””ë ‰í† ë¦¬ ì œê±°
rm -rf ~/kubespray
```


# 3.2. ëª¨ë“  í˜¸ìŠ¤íŠ¸ repo update
* í•„ìˆ˜ ì•„ë‹˜. repoìƒíƒœ ì•ˆì¢‹ì„ë•Œë§Œ,
```
hosts=("vm01" "vm02" "vm03")
for host in "${hosts[@]}"; do
  echo "Connecting to $host ..."
  ssh "$host" << EOF
    # apt update ë° repository ì¶”ê°€
    sudo apt update
    REPO_LINE="deb http://mirror.kakao.com/ubuntu/ noble main universe"
    if ! grep -Fxq "\$REPO_LINE" /etc/apt/sources.list; then
      echo "\$REPO_LINE" | sudo tee -a /etc/apt/sources.list
      echo "Repository line added successfully."
    else
      echo "Repository line already exists."
    fi
    sudo apt-get update
EOF
  if [ $? -eq 0 ]; then
    echo "Script executed successfully on $host."
  else
    echo "Failed to execute script on $host."
  fi
done
#cf : deb http://ftp.daum.net/ubuntu/ noble main universe

```

* cf) ì•„ë˜ì™€ ê°™ì´ /etc/hostsíŒŒì¼ì„ ì§ì ‘ ì…‹íŒ… í•´ë„ ë¨
```
52.213.183.141 vm01
54.75.118.15   vm02
54.75.118.154  vm03
```

## 4. git Clone
```
cd ~
git clone -b release-2.28 https://github.com/kubernetes-sigs/kubespray
cd kubespray
```

## 5. inventoryíŒŒì¼ ìƒì„±
```
cat > inventory/inventory.ini <<'EOF'
[all]
vm01 ansible_host=vm01 etcd_member_name=etcd1
vm02 ansible_host=vm02
vm03 ansible_host=vm03

[kube_control_plane]
vm01
vm02

[etcd]
vm01

[kube_node]
vm01
vm02
vm03

[k8s_cluster:children]
kube_control_plane
kube_node
EOF
```

### 6. EC2 ì„¤ì • ìƒì„± (í•µì‹¬!)
```bash
mkdir -p inventory/group_vars/all

# ìµœì†Œ í•„ìˆ˜ ì„¤ì •ë§Œ í¬í•¨
cat > inventory/group_vars/all/all.yml <<'EOF'
# EC2 í”„ë¼ì´ë¹— IP ping ì²´í¬ ë¹„í™œì„±í™” (EC2 í•„ìˆ˜!)
ping_access_ip: false
wait_for_services_timeout: 900
kube_apiserver_request_timeout: "90s"
EOF
```

### 7. ë…¸ë“œ ì—°ê²° í™•ì¸ (ì„ íƒì‚¬í•­)
```bash
# ëª¨ë“  ë…¸ë“œì— ì—°ê²° ê°€ëŠ¥í•œì§€ í™•ì¸
ansible -i inventory/inventory.ini all -m ping
```

## 8. kubesparyInstall.sh ì‹¤í–‰
* pip errorì‹œ requirements.txtíŒŒì¼ì—ì„œ ì—ëŸ¬ê°€ ë°œìƒí•˜ëŠ” í˜í‚¤ì§€ì˜ "=="ë¶€í„° ì¤„ì˜ ëê¹Œì§€ ì œê±°.
* python3.12ë²„ì „ì—ì„œëŠ” --break-system-packages ì˜µì…˜ í•„ìš”. 
```
sudo apt remove -y python3-jsonschema # ubuntu24.04ì—ì„œë§Œ 
sudo python -m pip install --break-system-packages -r requirements.txt

ansible-playbook --flush-cache -u ubuntu -b --become --become-user=root \
  -i inventory/inventory.ini -v \
  --private-key ~/.ssh/id_rsa \
  cluster.yml 

```

# ğŸ” ìë™ ì„¤ì¹˜ ì»´í¬ë„ŒíŠ¸

Kubesprayê°€ ìë™ìœ¼ë¡œ ì„¤ì¹˜í•˜ëŠ” container runtime ë„êµ¬ë“¤:
- **containerd**: ë©”ì¸ container runtime
- **runc**: OCI í‘œì¤€ runtime
- **crictl**: CRI ë””ë²„ê¹… ë„êµ¬
- **nerdctl**: Docker í˜¸í™˜ CLI

# âœ… ì„¤ì¹˜ í™•ì¸

## í´ëŸ¬ìŠ¤í„° ìƒíƒœ í™•ì¸
```bash
ssh vm01 'sudo kubectl get nodes'
```

## Container Runtime í™•ì¸
```bash
for node in vm01 vm02 vm03; do
  echo "=== $node ==="
  ssh $node 'which containerd && containerd --version'
done
```

## Pod ë¶„ì‚° í…ŒìŠ¤íŠ¸
```bash
ssh vm01 'sudo kubectl create deployment test-nginx --image=nginx:latest --replicas=6'
sleep 10
ssh vm01 'sudo kubectl get pods -o wide'

# ssh vm01 'sudo kubectl delete deployment test-nginx'
```

# ğŸš¨ ì£¼ì˜ì‚¬í•­

1. **EC2 í•„ìˆ˜ ì„¤ì •**: `ping_access_ip: false` ë°˜ë“œì‹œ ì„¤ì •
2. **ì²« ì‹¤í–‰ ì‹œê°„**: ë°”ì´ë„ˆë¦¬ ë‹¤ìš´ë¡œë“œë¡œ ì¸í•´ 20-25ë¶„ ì†Œìš”
3. **ë„¤íŠ¸ì›Œí¬ ì˜ì¡´ì„±**: ì•ˆì •ì ì¸ ì¸í„°ë„· ì—°ê²° í•„ìš”
4. **ë©”ëª¨ë¦¬ ìš”êµ¬ì‚¬í•­**: ê° ë…¸ë“œ ìµœì†Œ 2GB RAM ê¶Œì¥



# Admin
## Shutdown All Instance
```
for i in $(seq 3); do ssh ubuntu@vm0$i sudo sh -c 'shutdown -h now'; done
```
## Startup all Instance
```
ids=$(aws ec2 describe-instances  --filters "Name=tag-value,Values=vm0*" --query "Reservations[].Instances[].InstanceId" --output text)
for i in $ids; do     aws ec2 start-instances --instance-ids $i ;done
```

## vm destroy
```
terraform destroy --auto-approve
```
